{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying safe loans with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [LendingClub](https://www.lendingclub.com/) is a peer-to-peer leading company that directly connects borrowers and potential lenders/investors. In this notebook, you will build a classification model to predict whether or not a loan provided by LendingClub is likely to [default](https://en.wikipedia.org/wiki/Default_(finance)).\n",
    "\n",
    "In this notebook you will use data from the LendingClub to predict whether a loan will be paid off in full or the loan will be [charged off](https://en.wikipedia.org/wiki/Charge-off) and possibly go into default. In this assignment you will:\n",
    "\n",
    "* Use SFrames to do some feature engineering.\n",
    "* Train a decision-tree on the LendingClub dataset.\n",
    "* Visualize the tree.\n",
    "* Predict whether a loan will default along with prediction probabilities (on a validation set).\n",
    "* Train a complex tree model and compare it to simple tree model.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire up Graphlab Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of GraphLab Create. If you don't find the decision tree module, then you would need to upgrade GraphLab Create using\n",
    "\n",
    "```\n",
    "   pip install graphlab-create --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LendingClub dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a dataset from the [LendingClub](https://www.lendingclub.com/). A parsed and cleaned form of the dataset is availiable [here](https://github.com/learnml/machine-learning-specialization-private). Make sure you **download the dataset** before running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2705: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring some features\n",
    "\n",
    "Let's quickly explore what the dataset looks like. First, let's print out the column names to see what features we have in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
       "       'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n",
       "       'is_inc_v', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc',\n",
       "       'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq',\n",
       "       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'initial_list_status', 'out_prncp',\n",
       "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv',\n",
       "       'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee',\n",
       "       'recoveries', 'collection_recovery_fee', 'last_pymnt_d',\n",
       "       'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
       "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
       "       'policy_code', 'not_compliant', 'status', 'inactive_loans',\n",
       "       'bad_loans', 'emp_length_num', 'grade_num', 'sub_grade_num',\n",
       "       'delinq_2yrs_zero', 'pub_rec_zero', 'collections_12_mths_zero',\n",
       "       'short_emp', 'payment_inc_ratio', 'final_d', 'last_delinq_none',\n",
       "       'last_record_none', 'last_major_derog_none'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that we have some feature columns that have to do with grade of the loan, annual income, home ownership status, etc. Let's take a look at the distribution of loan grades in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    C\n",
       "2    C\n",
       "3    C\n",
       "4    A\n",
       "5    E\n",
       "6    F\n",
       "7    B\n",
       "8    C\n",
       "9    B\n",
       "Name: grade, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['grade'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that over half of the loan grades are assigned values `B` or `C`. Each loan is assigned one of these grades, along with a more finely discretized feature called `sub_grade` (feel free to explore that feature column as well!). These values depend on the loan application and credit report, and determine the interest rate of the loan. More information can be found [here](https://www.lendingclub.com/public/rates-and-fees.action).\n",
    "\n",
    "Now, let's look at a different feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             RENT\n",
       "1             RENT\n",
       "2             RENT\n",
       "3             RENT\n",
       "4             RENT\n",
       "5             RENT\n",
       "6              OWN\n",
       "7             RENT\n",
       "8              OWN\n",
       "9              OWN\n",
       "10            RENT\n",
       "11            RENT\n",
       "12            RENT\n",
       "13            RENT\n",
       "14            RENT\n",
       "15        MORTGAGE\n",
       "16        MORTGAGE\n",
       "17            RENT\n",
       "18            RENT\n",
       "19             OWN\n",
       "20            RENT\n",
       "21            RENT\n",
       "22        MORTGAGE\n",
       "23            RENT\n",
       "24            RENT\n",
       "25        MORTGAGE\n",
       "26            RENT\n",
       "27        MORTGAGE\n",
       "28        MORTGAGE\n",
       "29            RENT\n",
       "            ...   \n",
       "122577        RENT\n",
       "122578    MORTGAGE\n",
       "122579    MORTGAGE\n",
       "122580        RENT\n",
       "122581        RENT\n",
       "122582    MORTGAGE\n",
       "122583        RENT\n",
       "122584        RENT\n",
       "122585         OWN\n",
       "122586    MORTGAGE\n",
       "122587    MORTGAGE\n",
       "122588         OWN\n",
       "122589    MORTGAGE\n",
       "122590         OWN\n",
       "122591    MORTGAGE\n",
       "122592        RENT\n",
       "122593    MORTGAGE\n",
       "122594         OWN\n",
       "122595    MORTGAGE\n",
       "122596    MORTGAGE\n",
       "122597    MORTGAGE\n",
       "122598    MORTGAGE\n",
       "122599    MORTGAGE\n",
       "122600        RENT\n",
       "122601    MORTGAGE\n",
       "122602    MORTGAGE\n",
       "122603    MORTGAGE\n",
       "122604    MORTGAGE\n",
       "122605    MORTGAGE\n",
       "122606         OWN\n",
       "Name: home_ownership, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['home_ownership']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature describes whether the loanee is mortaging, renting, or owns a home. We can see that a small percentage of the loanees own a home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the target column\n",
    "\n",
    "The target column (label column) of the dataset that we are interested in is called `bad_loans`. In this column **1** means a risky (bad) loan **0** means a safe  loan.\n",
    "\n",
    "In order to make this more intuitive and consistent with the lectures, we reassign the target to be:\n",
    "* **+1** as a safe  loan, \n",
    "* **-1** as a risky (bad) loan. \n",
    "\n",
    "We put this in a new column called `safe_loans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# safe_loans =  1 => safe\n",
    "# safe_loans = -1 => risky\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore the distribution of the column `safe_loans`. This gives us a sense of how many safe and risky loans are present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.811185\n",
       "-1    0.188815\n",
       "Name: safe_loans, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['safe_loans'].value_counts()/loans.shape[0]\n",
    "#loans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have:\n",
    "* Around 81% safe loans\n",
    "* Around 19% risky loans\n",
    "\n",
    "It looks like most of these loans are safe loans (thankfully). But this does make our problem of identifying risky loans challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for the classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be using a subset of features (categorical and numeric). The features we will be using are **described in the code comments** below. If you are a finance geek, the [LendingClub](https://www.lendingclub.com/) website has a lot more details about these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['grade',                     # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "\n",
    "target = 'safe_loans'                   # prediction target (y) (+1 means safe, -1 is risky)\n",
    "\n",
    "# Extract the feature columns and target column\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remains now is a **subset of features** and the **target** that we will use for the rest of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data to balance classes\n",
    "\n",
    "As we explored above, our data is disproportionally full of safe loans.  Let's create two datasets: one with just the safe loans (`safe_loans_raw`) and one with just the risky loans (`risky_loans_raw`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of safe loans  : 99457\n",
      "Number of risky loans : 23150\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == +1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "print(\"Number of safe loans  : %s\" % len(safe_loans_raw))\n",
    "print(\"Number of risky loans : %s\" % len(risky_loans_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write some code to compute below the percentage of safe and risky loans in the dataset and validate these numbers against what was given using `.show` earlier in the assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans  : 0.8111853319957262\n",
      "Percentage of risky loans : 0.18881466800427382\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of safe loans  : %s\" % (len(safe_loans_raw)/len(loans))) \n",
    "print(\"Percentage of risky loans : %s\" % (len(risky_loans_raw)/len(loans)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to combat class imbalance is to undersample the larger class until the class distribution is approximately half and half. Here, we will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We used `seed=1` so everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Since there are fewer risky loans than safe loans, find the ratio of the sizes\n",
    "# # and use that percentage to undersample the safe loans.\n",
    "# percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "\n",
    "# risky_loans = risky_loans_raw\n",
    "# safe_loans = safe_loans_raw.sample(percentage, seed=1)\n",
    "\n",
    "# Append the risky_loans with the downsampled version of safe_loans\n",
    "# loans_data = risky_loans.append(safe_loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify that the resulting percentage of safe and risky loans are each nearly 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print \"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data))\n",
    "#print \"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data))\n",
    "#print \"Total number of loans in our new dataset :\", len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are many approaches for dealing with imbalanced data, including some where we modify the learning algorithm. These approaches are beyond the scope of this course, but some of them are reviewed in this [paper](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5128907&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F69%2F5173046%2F05128907.pdf%3Farnumber%3D5128907 ). For this assignment, we use the simplest possible approach, where we subsample the overly represented class to get a more balanced dataset. In general, and especially when the data is highly imbalanced, we recommend using more advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = []\n",
    "loans_str = loans.select_dtypes(include = ['object'])\n",
    "for feat_name in loans_str.columns.values.tolist():\n",
    "    categorical_variables.append(feat_name)\n",
    "\n",
    "for feature in categorical_variables:\n",
    "    loans_data_unpacked = pd.get_dummies(loans[feature],prefix=feature)\n",
    "    loans.drop(feature,axis=1,inplace=True)\n",
    "    loans[loans_data_unpacked.columns.values.tolist()]=loans_data_unpacked   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load JSON files (see Assignement 2 of Week2)\n",
    "import json\n",
    "with open('module-5-assignment-1-train-idx.json', 'r') as f: \n",
    "    train_idx = json.load(f)\n",
    "with open('module-5-assignment-1-validation-idx.json', 'r') as f: \n",
    "    validation_idx = json.load(f)\n",
    "\n",
    "#train_data = products.iloc[train_idx,:]\n",
    "#validation_data = products.iloc[validation_idx]\n",
    "\n",
    "train_data = loans.iloc[train_idx]\n",
    "validation_data = loans.iloc[validation_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify that the resulting percentage of safe and risky loans are each nearly 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                 : 0.5036535568450462\n",
      "Percentage of risky loans                : 0.4963464431549538\n",
      "Total number of loans in our new dataset : 46508\n"
     ]
    }
   ],
   "source": [
    "train_data.shape\n",
    "train_data.head()\n",
    "print(\"Percentage of safe loans                 :\", len(train_data[train_data['safe_loans']==1]) / float(len(train_data)))\n",
    "print(\"Percentage of risky loans                :\", len(train_data[train_data['safe_loans']==-1]) / float(len(train_data)))\n",
    "print(\"Total number of loans in our new dataset :\", (len(train_data)+len(validation_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use decision tree to build a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the built-in GraphLab Create decision tree learner to create a loan prediction model on the training data. (In the next assignment, you will implement your own decision tree learning algorithm.)  Our feature columns and target column have already been decided above. Use `validation_set=None` to get the same results as everyone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...,  1  1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train_data = train_data.sort_values(by = target, ascending = True)\n",
    "y = train_data[target].as_matrix()\n",
    "print(y)\n",
    "X = train_data.ix[:,train_data.columns!=target].as_matrix()\n",
    "decision_tree_model=DecisionTreeClassifier(max_depth=6)\n",
    "decision_tree_model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the [documentation](https://dato.com/products/create/docs/generated/graphlab.boosted_trees_classifier.create.html#graphlab.boosted_trees_classifier.create), typically the max depth of the tree is capped at 6. However, such a tree can be hard to visualize graphically.  Here, we instead learn a smaller model with **max depth of 2** to gain some intuition by visualizing the learned tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model=DecisionTreeClassifier(max_depth=2)\n",
    "small_model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "\n",
    "Let's consider two positive and two negative examples **from the validation set** and see what the model predicts. We will do the following:\n",
    "* Predict whether or not a loan is safe.\n",
    "* Predict the probability that a loan is safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    short_emp  emp_length_num    dti  last_delinq_none  last_major_derog_none  \\\n",
       "19          0              11  11.18                 1                      1   \n",
       "79          0              10  16.85                 1                      1   \n",
       "24          0               3  13.97                 0                      1   \n",
       "41          0              11  16.33                 1                      1   \n",
       "\n",
       "    revol_util  total_rec_late_fee  safe_loans  grade_A  grade_B  \\\n",
       "19        82.4                 0.0           1      0.0      1.0   \n",
       "79        96.4                 0.0           1      0.0      0.0   \n",
       "24        59.5                 0.0          -1      0.0      0.0   \n",
       "41        62.1                 0.0          -1      1.0      0.0   \n",
       "\n",
       "         ...         purpose_house  purpose_major_purchase  purpose_medical  \\\n",
       "19       ...                   0.0                     0.0              0.0   \n",
       "79       ...                   0.0                     0.0              0.0   \n",
       "24       ...                   0.0                     0.0              0.0   \n",
       "41       ...                   0.0                     0.0              0.0   \n",
       "\n",
       "    purpose_moving  purpose_other  purpose_small_business  purpose_vacation  \\\n",
       "19             0.0            0.0                     0.0               0.0   \n",
       "79             0.0            0.0                     0.0               0.0   \n",
       "24             0.0            1.0                     0.0               0.0   \n",
       "41             0.0            0.0                     0.0               0.0   \n",
       "\n",
       "    purpose_wedding  term_ 36 months  term_ 60 months  \n",
       "19              0.0              1.0              0.0  \n",
       "79              0.0              1.0              0.0  \n",
       "24              0.0              0.0              1.0  \n",
       "41              0.0              1.0              0.0  \n",
       "\n",
       "[4 rows x 68 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "\n",
    "sample_validation_data_risky = validation_risky_loans[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans[0:2]\n",
    "\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "sample_validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore label predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use our model  to predict whether or not a loan is likely to default. For each row in the **sample_validation_data**, use the **decision_tree_model** to predict whether or not the loan is classified as a **safe loan**. \n",
    "\n",
    "**Hint:** Be sure to use the `.predict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pred  safe_loans\n",
      "19     1           1\n",
      "79    -1           1\n",
      "24    -1          -1\n",
      "41     1          -1\n"
     ]
    }
   ],
   "source": [
    "newX=sample_validation_data.ix[:,sample_validation_data.columns!=target].as_matrix()\n",
    "sample_validation_data['pred'] = decision_tree_model.predict(newX)\n",
    "print(sample_validation_data[['pred','safe_loans']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What percentage of the predictions on `sample_validation_data` did `decision_tree_model` get correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore probability predictions\n",
    "\n",
    "For each row in the **sample_validation_data**, what is the probability (according **decision_tree_model**) of a loan being classified as **safe**? \n",
    "\n",
    "\n",
    "**Hint:** Set `output_type='probability'` to make **probability** predictions using **decision_tree_model** on `sample_validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pred  pred_proba  safe_loans\n",
      "19     1    0.658435           1\n",
      "79    -1    0.463694           1\n",
      "24    -1    0.352490          -1\n",
      "41     1    0.792105          -1\n"
     ]
    }
   ],
   "source": [
    "sample_validation_data['pred_proba'] = decision_tree_model.predict_proba(newX)[:,1]\n",
    "print(sample_validation_data[['pred','pred_proba','safe_loans']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Which loan has the highest probability of being classified as a **safe loan**?\n",
    "\n",
    "**Checkpoint:** Can you verify that for all the predictions with `probability >= 0.5`, the model predicted the label **+1**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tricky predictions!\n",
    "\n",
    "Now, we will explore something pretty interesting. For each row in the **sample_validation_data**, what is the probability (according to **small_model**) of a loan being classified as **safe**?\n",
    "\n",
    "**Hint:** Set `output_type='probability'` to make **probability** predictions using **small_model** on `sample_validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58103415,  0.40744661,  0.40744661,  0.76879888])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.predict_proba(newX)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Notice that the probability preditions are the **exact same** for the 2nd and 3rd loans. Why would this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the prediction on a tree\n",
    "\n",
    "\n",
    "Note that you should be able to look at the small tree, traverse it yourself, and visualize the prediction being made. Consider the following point in the **sample_validation_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_emp                      0.000000\n",
       "emp_length_num                10.000000\n",
       "dti                           16.850000\n",
       "last_delinq_none               1.000000\n",
       "last_major_derog_none          1.000000\n",
       "revol_util                    96.400000\n",
       "total_rec_late_fee             0.000000\n",
       "safe_loans                     1.000000\n",
       "grade_A                        0.000000\n",
       "grade_B                        0.000000\n",
       "grade_C                        0.000000\n",
       "grade_D                        1.000000\n",
       "grade_E                        0.000000\n",
       "grade_F                        0.000000\n",
       "grade_G                        0.000000\n",
       "sub_grade_A1                   0.000000\n",
       "sub_grade_A2                   0.000000\n",
       "sub_grade_A3                   0.000000\n",
       "sub_grade_A4                   0.000000\n",
       "sub_grade_A5                   0.000000\n",
       "sub_grade_B1                   0.000000\n",
       "sub_grade_B2                   0.000000\n",
       "sub_grade_B3                   0.000000\n",
       "sub_grade_B4                   0.000000\n",
       "sub_grade_B5                   0.000000\n",
       "sub_grade_C1                   0.000000\n",
       "sub_grade_C2                   0.000000\n",
       "sub_grade_C3                   0.000000\n",
       "sub_grade_C4                   0.000000\n",
       "sub_grade_C5                   0.000000\n",
       "                                ...    \n",
       "sub_grade_F1                   0.000000\n",
       "sub_grade_F2                   0.000000\n",
       "sub_grade_F3                   0.000000\n",
       "sub_grade_F4                   0.000000\n",
       "sub_grade_F5                   0.000000\n",
       "sub_grade_G1                   0.000000\n",
       "sub_grade_G2                   0.000000\n",
       "sub_grade_G3                   0.000000\n",
       "sub_grade_G4                   0.000000\n",
       "sub_grade_G5                   0.000000\n",
       "home_ownership_MORTGAGE        0.000000\n",
       "home_ownership_OTHER           0.000000\n",
       "home_ownership_OWN             0.000000\n",
       "home_ownership_RENT            1.000000\n",
       "purpose_car                    0.000000\n",
       "purpose_credit_card            0.000000\n",
       "purpose_debt_consolidation     1.000000\n",
       "purpose_home_improvement       0.000000\n",
       "purpose_house                  0.000000\n",
       "purpose_major_purchase         0.000000\n",
       "purpose_medical                0.000000\n",
       "purpose_moving                 0.000000\n",
       "purpose_other                  0.000000\n",
       "purpose_small_business         0.000000\n",
       "purpose_vacation               0.000000\n",
       "purpose_wedding                0.000000\n",
       "term_ 36 months                1.000000\n",
       "term_ 60 months                0.000000\n",
       "pred                          -1.000000\n",
       "pred_proba                     0.463694\n",
       "Name: 79, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_validation_data.iloc[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the small tree here to do the traversing for this data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.predict(newX)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the tree visualization above, the values at the leaf nodes are not class predictions but scores (a slightly advanced concept that is out of the scope of this course). You can read more about this [here](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf).  If the score is $\\geq$ 0, the class +1 is predicted.  Otherwise, if the score < 0, we predict class -1.\n",
    "\n",
    "\n",
    "**Quiz Question:** Based on the visualized tree, what prediction would you make for this data point?\n",
    "\n",
    "Now, let's verify your prediction by examining the prediction made using GraphLab Create.  Use the `.predict` function on `small_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating accuracy of the decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the accuracy is defined as follows:\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Let us start by evaluating the accuracy of the `small_model` and `decision_tree_model` on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613502041694\n",
      "0.640527616591\n"
     ]
    }
   ],
   "source": [
    "print(small_model.score(X,y))\n",
    "print(decision_tree_model.score(X,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** You should see that the **small_model** performs worse than the **decision_tree_model** on the training data.\n",
    "\n",
    "\n",
    "Now, let us evaluate the accuracy of the **small_model** and **decision_tree_model** on the entire **validation_data**, not just the subsample considered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.619345109866\n",
      "0.636148211978\n"
     ]
    }
   ],
   "source": [
    "newX=validation_data.ix[:,validation_data.columns!=target].as_matrix()\n",
    "newy=validation_data[target].as_matrix()\n",
    "print(small_model.score(newX,newy))\n",
    "print(decision_tree_model.score(newX,newy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Quiz Question:** What is the accuracy of `decision_tree_model` on the validation set, rounded to the nearest .01?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating accuracy of a complex decision tree model\n",
    "\n",
    "Here, we will train a large decision tree with `max_depth=10`. This will allow the learned tree to become very deep, and result in a very complex model. Recall that in lecture, we prefer simpler models with similar predictive power. This will be an example of a more complicated model which has similar predictive power, i.e. something we don't want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model=DecisionTreeClassifier(max_depth=10)\n",
    "big_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us evaluate **big_model** on the training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66379217709\n",
      "0.626669538992\n"
     ]
    }
   ],
   "source": [
    "print(big_model.score(X,y))\n",
    "print(big_model.score(newX,newy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** We should see that **big_model** has even better performance on the training set than **decision_tree_model** did on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** How does the performance of **big_model** on the validation set compare to **decision_tree_model** on the validation set? Is this a sign of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying the cost of mistakes\n",
    "\n",
    "Every mistake the model makes costs money. In this section, we will try and quantify the cost of each mistake made by the model.\n",
    "\n",
    "Assume the following:\n",
    "\n",
    "* **False negatives**: Loans that were actually safe but were predicted to be risky. This results in an oppurtunity cost of losing a loan that would have otherwise been accepted. \n",
    "* **False positives**: Loans that were actually risky but were predicted to be safe. These are much more expensive because it results in a risky loan being given. \n",
    "* **Correct predictions**: All correct predictions don't typically incur any cost.\n",
    "\n",
    "\n",
    "Let's write code that can compute the cost of mistakes made by the model. Complete the following 4 steps:\n",
    "1. First, let us compute the predictions made by the model.\n",
    "1. Second, compute the number of false positives.\n",
    "2. Third, compute the number of false negatives.\n",
    "3. Finally, compute the cost of mistakes made by the model by adding up the costs of true positives and false positives.\n",
    "\n",
    "First, let us make predictions on `validation_data` using the `decision_tree_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ..., -1, -1,  1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = decision_tree_model.predict(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False positives** are predictions where the model predicts +1 but the true label is -1. Complete the following code block for the number of false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "validation_data['pred']=predictions\n",
    "validation_data[['pred','safe_loans']].head()\n",
    "FP=validation_data[validation_data['pred']==1][validation_data['safe_loans']==-1]\n",
    "numFP=len(FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False negatives** are predictions where the model predicts -1 but the true label is +1. Complete the following code block for the number of false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "FN=validation_data[validation_data['pred']==-1][validation_data['safe_loans']==1]\n",
    "numFN=len(FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Let us assume that each mistake costs money:\n",
    "* Assume a cost of \\$10,000 per false negative.\n",
    "* Assume a cost of \\$20,000 per false positive.\n",
    "\n",
    "What is the total cost of mistakes made by `decision_tree_model` on `validation_data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50390000\n"
     ]
    }
   ],
   "source": [
    "cost=10000*numFN+20000*numFP\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
